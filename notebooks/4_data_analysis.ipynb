{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple data analysis for numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load the data and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/epi-recipes-num.csv')\n",
    "df2 = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_outliers(data, m=1):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17064, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['calories'] = rm_outliers(df2['nutritions.Calories'])\n",
    "df2['calories'] = rm_outliers(df2['calories'])\n",
    "df3 = df2.dropna()\n",
    "df3 = df3.drop(['calories'], axis=1)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17064, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"RRR\"] = ((df3['nutritions.Protein']/50 + df3['nutritions.Fiber']/25)/2) / ((df3['nutritions.Calories']/2000 + df3['nutritions.Saturated Fat']/20 + df3['nutritions.Cholesterol']/300 + df3['nutritions.Carbohydrates']/300 + df3['nutritions.Sodium']/2400)/5)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df3[['nutritions.Calories', 'nutritions.Carbohydrates','nutritions.Cholesterol', 'nutritions.Fat', 'nutritions.Fiber','nutritions.Monounsaturated Fat', 'nutritions.Polyunsaturated Fat','nutritions.Protein', 'nutritions.Saturated Fat', 'nutritions.Sodium']]\n",
    "target = df3['healthy']\n",
    "rrr = np.array(df3['RRR']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17064, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2).fit(data).transform(data)\n",
    "pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0512697796286844"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(normalize=True)\n",
    "reg.fit(data, target)\n",
    "reg.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reg.predict(data)>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05236463326332452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2 = LinearRegression(normalize=True)\n",
    "reg2.fit(rrr, target)\n",
    "reg2.score(rrr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reg2.predict(rrr)>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00760514904778964"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3 = LinearRegression(normalize=True)\n",
    "reg3.fit(pca, target)\n",
    "reg3.score(pca, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reg3.predict(pca)>0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272737927801219"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(data, target)\n",
    "logreg.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       0.36      0.01      0.02      1233\n",
      "\n",
      "avg / total       0.89      0.93      0.89     17064\n",
      " 28\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(target, logreg.predict(data)), sum(logreg.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265119549929677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(rrr, target)\n",
    "logreg2.score(rrr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       0.30      0.01      0.02      1233\n",
      "\n",
      "avg / total       0.88      0.93      0.89     17064\n",
      " 53\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, logreg2.predict(rrr)), sum(logreg2.predict(rrr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9273909985935302"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg3 = LogisticRegression()\n",
    "logreg3.fit(pca, target)\n",
    "logreg3.score(pca, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       0.00      0.00      0.00      1233\n",
      "\n",
      "avg / total       0.86      0.93      0.89     17064\n",
      " 6\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, logreg3.predict(pca)), sum(logreg3.predict(pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289732770745429"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth=8, random_state=12345)\n",
    "rf.fit(data, target)\n",
    "rf.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       1.00      0.02      0.03      1233\n",
      "\n",
      "avg / total       0.93      0.93      0.90     17064\n",
      " 21\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, rf.predict(data)), sum(rf.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281528363806845"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=8, random_state=12345)\n",
    "rf2.fit(rrr, target)\n",
    "rf2.score(rrr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       0.89      0.01      0.01      1233\n",
      "\n",
      "avg / total       0.93      0.93      0.89     17064\n",
      " 9\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, rf2.predict(rrr)), sum(rf2.predict(rrr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279184247538678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf3 = RandomForestClassifier(max_depth=8, random_state=12345)\n",
    "rf3.fit(pca, target)\n",
    "rf3.score(pca, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      1.00      0.96     15831\n",
      "       True       1.00      0.00      0.00      1233\n",
      "\n",
      "avg / total       0.93      0.93      0.89     17064\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, rf3.predict(pca)), sum(rf3.predict(pca)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. resample for unbalance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_h = df3[df3.healthy == 1]\n",
    "df_n = df3[df3.healthy == 0]\n",
    "len(df_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8532"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(len(df3)/2)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17064, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample, shuffle\n",
    "df_h2 = resample(df_h, replace = True, n_samples = n, random_state = 100)\n",
    "df_n2 = resample(df_n, replace = True, n_samples = n, random_state = 100)\n",
    "df4 = df_h2.append(df_n2)\n",
    "df4 = shuffle(df4, random_state = 100)\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df4[['nutritions.Calories', 'nutritions.Carbohydrates','nutritions.Cholesterol', 'nutritions.Fat', 'nutritions.Fiber','nutritions.Monounsaturated Fat', 'nutritions.Polyunsaturated Fat','nutritions.Protein', 'nutritions.Saturated Fat', 'nutritions.Sodium']]\n",
    "target2 = df4['healthy']\n",
    "rrr2 = np.array(df4['RRR']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. rebuild model based on resampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20469164894330016"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression(normalize=True)\n",
    "reg.fit(data2, target2)\n",
    "reg.score(data2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9797"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reg.predict(data2)>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15430778042139415"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg2 = LinearRegression(normalize=True)\n",
    "reg2.fit(rrr2, target2)\n",
    "reg2.score(rrr2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7482"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(reg2.predict(rrr2)>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7163619315518049"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(data2, target2)\n",
    "logreg.score(data2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.74      0.67      0.70      8532\n",
      "       True       0.70      0.77      0.73      8532\n",
      "\n",
      "avg / total       0.72      0.72      0.72     17064\n",
      " 9382\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target2, logreg.predict(data2)), sum(logreg.predict(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831926863572433"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(rrr2, target2)\n",
    "logreg2.score(rrr2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.67      0.72      0.70      8532\n",
      "       True       0.70      0.64      0.67      8532\n",
      "\n",
      "avg / total       0.68      0.68      0.68     17064\n",
      " 7870\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target2, logreg2.predict(rrr2)), sum(logreg2.predict(rrr2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495663384903891"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=8, random_state=12345)\n",
    "rf.fit(data2, target2)\n",
    "rf.score(data2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.92      0.77      0.84      8532\n",
      "       True       0.80      0.93      0.86      8532\n",
      "\n",
      "avg / total       0.86      0.85      0.85     17064\n",
      " 9879\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target2, rf.predict(data2)), sum(rf.predict(data2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519924988279418"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=8, random_state=12345)\n",
    "rf2.fit(rrr2, target2)\n",
    "rf2.score(rrr2, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.79      0.68      0.73      8532\n",
      "       True       0.72      0.82      0.77      8532\n",
      "\n",
      "avg / total       0.76      0.75      0.75     17064\n",
      " 9730\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target2, rf2.predict(rrr2)), sum(rf2.predict(rrr2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. use the model to predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6729957805907173"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.74      0.85     15831\n",
      "       True       0.21      0.91      0.35      1233\n",
      "\n",
      "avg / total       0.93      0.75      0.81     17064\n",
      " 5274\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, rf.predict(data)), sum(rf.predict(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6729957805907173"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.score(rrr, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.98      0.66      0.79     15831\n",
      "       True       0.16      0.82      0.27      1233\n",
      "\n",
      "avg / total       0.92      0.67      0.75     17064\n",
      " 6359\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, rf2.predict(rrr)), sum(rf2.predict(rrr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = rf.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11790,  5274])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prob > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3591093513383067\n"
     ]
    }
   ],
   "source": [
    "for i in prob:\n",
    "    print(i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1926"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_tran = [1 if i[1] > 0.7 else 0 for i in prob]\n",
    "sum(prob_tran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.97      0.92      0.94     15831\n",
      "       True       0.37      0.58      0.45      1233\n",
      "\n",
      "avg / total       0.92      0.90      0.91     17064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, prob_tran))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comments: \n",
    "use resampled data to build a random forest with max_depth=8, and set the threshold=0.7, we can get 0.45 F1 for healthy label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "ocs = svm.OneClassSVM()\n",
    "ocs.fit(data2)\n",
    "y_pred = ocs.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = [1 if x==1 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.96      0.94      0.95     15831\n",
      "       True       0.41      0.52      0.46      1233\n",
      "\n",
      "avg / total       0.92      0.91      0.92     17064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocs2 = svm.OneClassSVM()\n",
    "ocs2.fit(rrr2)\n",
    "y_pred2 = ocs2.predict(rrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8201"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy2 = [1 if x==1 else 0 for x in y_pred2]\n",
    "sum(yy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.93      0.52      0.67     15831\n",
      "       True       0.08      0.52      0.14      1233\n",
      "\n",
      "avg / total       0.87      0.52      0.63     17064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(target, yy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
